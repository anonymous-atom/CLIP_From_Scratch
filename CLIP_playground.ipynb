{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from CLIP import CLIP"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Text Encoder....\n",
      "Loading Image Encoder....\n"
     ]
    }
   ],
   "source": [
    "from encoder import TextEncoder, ImageEncoder\n",
    "from projection_head import ProjectionHead\n",
    "\n",
    "text_encoder = TextEncoder()\n",
    "image_encoder = ImageEncoder()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T05:56:42.394404Z",
     "start_time": "2024-04-10T05:56:37.927559Z"
    }
   },
   "id": "d6cbddefa83d9269",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "t_projection = ProjectionHead(512)\n",
    "i_projection = ProjectionHead(768)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T05:56:42.424170Z",
     "start_time": "2024-04-10T05:56:42.397540Z"
    }
   },
   "id": "5027220deff1924",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "clip = CLIP(text_encoder, image_encoder, t_projection, i_projection)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T05:56:43.187916Z",
     "start_time": "2024-04-10T05:56:43.181292Z"
    }
   },
   "id": "568ce504b2dae58f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import requests\n",
    "# \n",
    "# url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "# text = \"Two dogs sleeping\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T14:33:28.430939Z",
     "start_time": "2024-04-09T14:33:28.416977Z"
    }
   },
   "id": "7543a0717a5c53ec",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# out = clip(image, text)\n",
    "# out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T14:33:28.446632Z",
     "start_time": "2024-04-09T14:33:28.432378Z"
    }
   },
   "id": "eefab0e0ff917416",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read data from CSV with 2 columns image, captions and each image has 5 captions, I want to use only one caption\n",
    "# Return different arrays for images and texts and make sure the order is the same\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('data/captions.csv', names=['image', 'captions'], header=None)\n",
    "\n",
    "# Group by 'image' and select the first 'caption' for each group\n",
    "grouped_data = data.groupby('image').first().reset_index()\n",
    "\n",
    "# Append 'data/Images' to each image name\n",
    "grouped_data['image'] = grouped_data['image'].apply(lambda x: 'data/Images/' + x)\n",
    "\n",
    "# Convert the 'image' and 'caption' columns to numpy arrays\n",
    "images = grouped_data['image'].to_numpy()\n",
    "captions = grouped_data['captions'].to_numpy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T05:56:46.983650Z",
     "start_time": "2024-04-10T05:56:46.827452Z"
    }
   },
   "id": "11b59ef8c0b8df10",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "images = images[:50]\n",
    "captions = captions[:50]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T07:42:53.838815Z",
     "start_time": "2024-04-10T07:42:53.832655Z"
    }
   },
   "id": "c849f7eee24946c8",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from train import CLIPDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "# \n",
    "# # Create sample array of texts and images\n",
    "# texts = [\"A photo of a dog\", \"A photo of a bird\"]\n",
    "# images = [\"images/dog.jpeg\", \"images/bird.jpg\"]\n",
    "\n",
    "# Create transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# Create dataset and dataloader\n",
    "dataset = CLIPDataset(captions, images, transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T07:42:55.142629Z",
     "start_time": "2024-04-10T07:42:55.133990Z"
    }
   },
   "id": "ddb1879fa601ec7f",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# for x in dataloader:\n",
    "#     print(x)\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T07:42:56.132407Z",
     "start_time": "2024-04-10T07:42:56.125888Z"
    }
   },
   "id": "39337260b7968c95",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 2.9951376914978027\n",
      "Epoch 0, Batch 1, Loss: 3.0591814517974854\n",
      "Epoch 0, Batch 2, Loss: 3.2445356051127114\n",
      "Epoch 0, Batch 3, Loss: 3.0767226219177246\n",
      "Epoch 0, Loss: 3.0767226219177246\n",
      "Epoch 1, Batch 0, Loss: 3.141519546508789\n",
      "Epoch 1, Batch 1, Loss: 3.2237559159596763\n",
      "Epoch 1, Batch 2, Loss: 3.3347324643816267\n",
      "Epoch 1, Batch 3, Loss: 3.6751158833503723\n",
      "Epoch 1, Loss: 3.6751158833503723\n",
      "Epoch 2, Batch 0, Loss: 3.701079845428467\n",
      "Epoch 2, Batch 1, Loss: 3.676063656806946\n",
      "Epoch 2, Batch 2, Loss: 3.6709263541481714\n",
      "Epoch 2, Batch 3, Loss: 3.4768966337045035\n",
      "Epoch 2, Loss: 3.4768966337045035\n",
      "Epoch 3, Batch 0, Loss: 3.4559492606383104\n",
      "Epoch 3, Batch 1, Loss: 3.4614257557051524\n",
      "Epoch 3, Batch 2, Loss: 3.4925103267033895\n",
      "Epoch 3, Batch 3, Loss: 3.4777611270546913\n",
      "Epoch 3, Loss: 3.4777611270546913\n",
      "Epoch 4, Batch 0, Loss: 3.4740990260068108\n",
      "Epoch 4, Batch 1, Loss: 3.4700889918539257\n",
      "Epoch 4, Batch 2, Loss: 3.4746300609488237\n",
      "Epoch 4, Batch 3, Loss: 3.3682191610336303\n",
      "Epoch 4, Loss: 3.3682191610336303\n",
      "Epoch 5, Batch 0, Loss: 3.368560859135219\n",
      "Epoch 5, Batch 1, Loss: 3.3730979399247603\n",
      "Epoch 5, Batch 2, Loss: 3.3658970127934995\n",
      "Epoch 5, Batch 3, Loss: 3.280650864044825\n",
      "Epoch 5, Loss: 3.280650864044825\n",
      "Epoch 6, Batch 0, Loss: 3.2763157749176024\n",
      "Epoch 6, Batch 1, Loss: 3.2724782870366025\n",
      "Epoch 6, Batch 2, Loss: 3.284516855522438\n",
      "Epoch 6, Batch 3, Loss: 3.2535837462970187\n",
      "Epoch 6, Loss: 3.2535837462970187\n",
      "Epoch 7, Batch 0, Loss: 3.271502001532193\n",
      "Epoch 7, Batch 1, Loss: 3.2676348447799684\n",
      "Epoch 7, Batch 2, Loss: 3.2714978418042584\n",
      "Epoch 7, Batch 3, Loss: 3.1935870461165905\n",
      "Epoch 7, Loss: 3.1935870461165905\n",
      "Epoch 8, Batch 0, Loss: 3.2017535838213833\n",
      "Epoch 8, Batch 1, Loss: 3.2090544665561005\n",
      "Epoch 8, Batch 2, Loss: 3.2221496956689015\n",
      "Epoch 8, Batch 3, Loss: 3.199345591995451\n",
      "Epoch 8, Loss: 3.199345591995451\n",
      "Epoch 9, Batch 0, Loss: 3.201517520724116\n",
      "Epoch 9, Batch 1, Loss: 3.21389492248234\n",
      "Epoch 9, Batch 2, Loss: 3.21606607009203\n",
      "Epoch 9, Batch 3, Loss: 3.159103290736675\n",
      "Epoch 9, Loss: 3.159103290736675\n",
      "Epoch 10, Batch 0, Loss: 3.167891570707647\n",
      "Epoch 10, Batch 1, Loss: 3.1754506471611204\n",
      "Epoch 10, Batch 2, Loss: 3.178866634535235\n",
      "Epoch 10, Batch 3, Loss: 3.1459679888053373\n",
      "Epoch 10, Loss: 3.1459679888053373\n",
      "Epoch 11, Batch 0, Loss: 3.156878912448883\n",
      "Epoch 11, Batch 1, Loss: 3.16117390471956\n",
      "Epoch 11, Batch 2, Loss: 3.1636818178156587\n",
      "Epoch 11, Batch 3, Loss: 3.1348198167979717\n",
      "Epoch 11, Loss: 3.1348198167979717\n",
      "Epoch 12, Batch 0, Loss: 3.1358333716587143\n",
      "Epoch 12, Batch 1, Loss: 3.1340767443180084\n",
      "Epoch 12, Batch 2, Loss: 3.1342655829354826\n",
      "Epoch 12, Batch 3, Loss: 3.0911261519560447\n",
      "Epoch 12, Loss: 3.0911261519560447\n",
      "Epoch 13, Batch 0, Loss: 3.100807359758413\n",
      "Epoch 13, Batch 1, Loss: 3.103742209849534\n",
      "Epoch 13, Batch 2, Loss: 3.1070179928432813\n",
      "Epoch 13, Batch 3, Loss: 3.0664710817592487\n",
      "Epoch 13, Loss: 3.0664710817592487\n",
      "Epoch 14, Batch 0, Loss: 3.0737709319382382\n",
      "Epoch 14, Batch 1, Loss: 3.0751543898006966\n",
      "Epoch 14, Batch 2, Loss: 3.0783600595037814\n",
      "Epoch 14, Batch 3, Loss: 3.0465478549400964\n",
      "Epoch 14, Loss: 3.0465478549400964\n",
      "Epoch 15, Batch 0, Loss: 3.0541791847494784\n",
      "Epoch 15, Batch 1, Loss: 3.05553866297968\n",
      "Epoch 15, Batch 2, Loss: 3.0615035323869613\n",
      "Epoch 15, Batch 3, Loss: 3.0281691001728177\n",
      "Epoch 15, Loss: 3.0281691001728177\n",
      "Epoch 16, Batch 0, Loss: 3.0363080364007216\n",
      "Epoch 16, Batch 1, Loss: 3.040618666193702\n",
      "Epoch 16, Batch 2, Loss: 3.0420980889405778\n",
      "Epoch 16, Batch 3, Loss: 3.0099904747570263\n",
      "Epoch 16, Loss: 3.0099904747570263\n",
      "Epoch 17, Batch 0, Loss: 3.0143885612487793\n",
      "Epoch 17, Batch 1, Loss: 3.019202722821917\n",
      "Epoch 17, Batch 2, Loss: 3.0235507891211713\n",
      "Epoch 17, Batch 3, Loss: 2.9970831738577948\n",
      "Epoch 17, Loss: 2.9970831738577948\n",
      "Epoch 18, Batch 0, Loss: 3.003891566028334\n",
      "Epoch 18, Batch 1, Loss: 3.0111294179349333\n",
      "Epoch 18, Batch 2, Loss: 3.0163204352060955\n",
      "Epoch 18, Batch 3, Loss: 2.9870474793409048\n",
      "Epoch 18, Loss: 2.9870474793409048\n",
      "Epoch 19, Batch 0, Loss: 2.989637744891179\n",
      "Epoch 19, Batch 1, Loss: 2.9912813275288315\n",
      "Epoch 19, Batch 2, Loss: 2.9952170109447045\n",
      "Epoch 19, Batch 3, Loss: 2.9725593253970146\n",
      "Epoch 19, Loss: 2.9725593253970146\n",
      "Epoch 20, Batch 0, Loss: 2.984524236785041\n",
      "Epoch 20, Batch 1, Loss: 2.9877133354908083\n",
      "Epoch 20, Batch 2, Loss: 2.9931999703487717\n",
      "Epoch 20, Batch 3, Loss: 2.9790963246708824\n",
      "Epoch 20, Loss: 2.9790963246708824\n",
      "Epoch 21, Batch 0, Loss: 2.9795086832607494\n",
      "Epoch 21, Batch 1, Loss: 2.981702821199284\n",
      "Epoch 21, Batch 2, Loss: 2.988893322560979\n",
      "Epoch 21, Batch 3, Loss: 2.9700646684928373\n",
      "Epoch 21, Loss: 2.9700646684928373\n",
      "Epoch 22, Batch 0, Loss: 2.975836522123787\n",
      "Epoch 22, Batch 1, Loss: 2.9785386628574795\n",
      "Epoch 22, Batch 2, Loss: 2.9832718621243486\n",
      "Epoch 22, Batch 3, Loss: 2.963759200728458\n",
      "Epoch 22, Loss: 2.963759200728458\n",
      "Epoch 23, Batch 0, Loss: 2.9719538880932714\n",
      "Epoch 23, Batch 1, Loss: 2.9772303446810295\n",
      "Epoch 23, Batch 2, Loss: 2.9849334854828684\n",
      "Epoch 23, Batch 3, Loss: 2.961980519195398\n",
      "Epoch 23, Loss: 2.961980519195398\n",
      "Epoch 24, Batch 0, Loss: 2.963360690578972\n",
      "Epoch 24, Batch 1, Loss: 2.963967982603579\n",
      "Epoch 24, Batch 2, Loss: 2.9666195830913504\n",
      "Epoch 24, Batch 3, Loss: 2.9483803761005403\n",
      "Epoch 24, Loss: 2.9483803761005403\n",
      "Epoch 25, Batch 0, Loss: 2.9516929482469463\n",
      "Epoch 25, Batch 1, Loss: 2.9528908040009294\n",
      "Epoch 25, Batch 2, Loss: 2.95391687027459\n",
      "Epoch 25, Batch 3, Loss: 2.9334225264879374\n",
      "Epoch 25, Loss: 2.9334225264879374\n",
      "Epoch 26, Batch 0, Loss: 2.9350218659355525\n",
      "Epoch 26, Batch 1, Loss: 2.9371977189801775\n",
      "Epoch 26, Batch 2, Loss: 2.9402525491803604\n",
      "Epoch 26, Batch 3, Loss: 2.9253334160204285\n",
      "Epoch 26, Loss: 2.9253334160204285\n",
      "Epoch 27, Batch 0, Loss: 2.9287383534492704\n",
      "Epoch 27, Batch 1, Loss: 2.929947666688399\n",
      "Epoch 27, Batch 2, Loss: 2.9322013726105562\n",
      "Epoch 27, Batch 3, Loss: 2.914064258337021\n",
      "Epoch 27, Loss: 2.914064258337021\n",
      "Epoch 28, Batch 0, Loss: 2.919790272164134\n",
      "Epoch 28, Batch 1, Loss: 2.9213819169161614\n",
      "Epoch 28, Batch 2, Loss: 2.923232198798138\n",
      "Epoch 28, Batch 3, Loss: 2.909044342822042\n",
      "Epoch 28, Loss: 2.909044342822042\n",
      "Epoch 29, Batch 0, Loss: 2.9122003378012242\n",
      "Epoch 29, Batch 1, Loss: 2.9150230530965127\n",
      "Epoch 29, Batch 2, Loss: 2.9186256863489874\n",
      "Epoch 29, Batch 3, Loss: 2.902825176715851\n",
      "Epoch 29, Loss: 2.902825176715851\n",
      "Epoch 30, Batch 0, Loss: 2.9072369957758375\n",
      "Epoch 30, Batch 1, Loss: 2.909399253423097\n",
      "Epoch 30, Batch 2, Loss: 2.909861603403479\n",
      "Epoch 30, Batch 3, Loss: 2.897260723575469\n",
      "Epoch 30, Loss: 2.897260723575469\n",
      "Epoch 31, Batch 0, Loss: 2.899936378479004\n",
      "Epoch 31, Batch 1, Loss: 2.901727381206694\n",
      "Epoch 31, Batch 2, Loss: 2.902650253040584\n",
      "Epoch 31, Batch 3, Loss: 2.888369780033827\n",
      "Epoch 31, Loss: 2.888369780033827\n",
      "Epoch 32, Batch 0, Loss: 2.8915172806081846\n",
      "Epoch 32, Batch 1, Loss: 2.8936432398282563\n",
      "Epoch 32, Batch 2, Loss: 2.9016329969158607\n",
      "Epoch 32, Batch 3, Loss: 2.8842511628613328\n",
      "Epoch 32, Loss: 2.8842511628613328\n",
      "Epoch 33, Batch 0, Loss: 2.887085837529118\n",
      "Epoch 33, Batch 1, Loss: 2.8882380492651643\n",
      "Epoch 33, Batch 2, Loss: 2.8906207596814193\n",
      "Epoch 33, Batch 3, Loss: 2.8749701047644898\n",
      "Epoch 33, Loss: 2.8749701047644898\n",
      "Epoch 34, Batch 0, Loss: 2.876099866672154\n",
      "Epoch 34, Batch 1, Loss: 2.8778895761655723\n",
      "Epoch 34, Batch 2, Loss: 2.880992601243712\n",
      "Epoch 34, Batch 3, Loss: 2.873606015103204\n",
      "Epoch 34, Loss: 2.873606015103204\n",
      "Epoch 35, Batch 0, Loss: 2.8760628674892668\n",
      "Epoch 35, Batch 1, Loss: 2.8768319386831473\n",
      "Epoch 35, Batch 2, Loss: 2.8806703032313528\n",
      "Epoch 35, Batch 3, Loss: 2.8666260043780007\n",
      "Epoch 35, Loss: 2.8666260043780007\n",
      "Epoch 36, Batch 0, Loss: 2.8694677615987843\n",
      "Epoch 36, Batch 1, Loss: 2.872505885280975\n",
      "Epoch 36, Batch 2, Loss: 2.8748752113913194\n",
      "Epoch 36, Batch 3, Loss: 2.860306087377909\n",
      "Epoch 36, Loss: 2.860306087377909\n",
      "Epoch 37, Batch 0, Loss: 2.8615545154417923\n",
      "Epoch 37, Batch 1, Loss: 2.8632542069753013\n",
      "Epoch 37, Batch 2, Loss: 2.865429927181724\n",
      "Epoch 37, Batch 3, Loss: 2.8544025452513444\n",
      "Epoch 37, Loss: 2.8544025452513444\n",
      "Epoch 38, Batch 0, Loss: 2.856116749881919\n",
      "Epoch 38, Batch 1, Loss: 2.8580485117899905\n",
      "Epoch 38, Batch 2, Loss: 2.859486533749488\n",
      "Epoch 38, Batch 3, Loss: 2.846059117561732\n",
      "Epoch 38, Loss: 2.846059117561732\n",
      "Epoch 39, Batch 0, Loss: 2.847157481369699\n",
      "Epoch 39, Batch 1, Loss: 2.8502689343464525\n",
      "Epoch 39, Batch 2, Loss: 2.8513905507213666\n",
      "Epoch 39, Batch 3, Loss: 2.8399494849145412\n",
      "Epoch 39, Loss: 2.8399494849145412\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from train import train\n",
    "\n",
    "optimizer = Adam(clip.parameters(), lr=1e-4)\n",
    "\n",
    "train(clip, dataloader, optimizer, 40)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T07:57:59.631496Z",
     "start_time": "2024-04-10T07:42:56.778903Z"
    }
   },
   "id": "e003b41dd908a79e",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "CLIP(\n  (text_encoder): TextEncoder(\n    (model): T5EncoderModel(\n      (shared): Embedding(32128, 512)\n      (encoder): T5Stack(\n        (embed_tokens): Embedding(32128, 512)\n        (block): ModuleList(\n          (0): T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): Linear(in_features=512, out_features=512, bias=False)\n                  (k): Linear(in_features=512, out_features=512, bias=False)\n                  (v): Linear(in_features=512, out_features=512, bias=False)\n                  (o): Linear(in_features=512, out_features=512, bias=False)\n                  (relative_attention_bias): Embedding(32, 8)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerFF(\n                (DenseReluDense): T5DenseActDense(\n                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): ReLU()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n          (1-5): 5 x T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): Linear(in_features=512, out_features=512, bias=False)\n                  (k): Linear(in_features=512, out_features=512, bias=False)\n                  (v): Linear(in_features=512, out_features=512, bias=False)\n                  (o): Linear(in_features=512, out_features=512, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerFF(\n                (DenseReluDense): T5DenseActDense(\n                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): ReLU()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (final_layer_norm): T5LayerNorm()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (image_encoder): ImageEncoder(\n    (model): ViTModel(\n      (embeddings): ViTEmbeddings(\n        (patch_embeddings): ViTPatchEmbeddings(\n          (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (encoder): ViTEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x ViTLayer(\n            (attention): ViTAttention(\n              (attention): ViTSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): ViTSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (intermediate): ViTIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): ViTOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          )\n        )\n      )\n      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (pooler): ViTPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (activation): Tanh()\n      )\n    )\n  )\n  (image_projection): ProjectionHead(\n    (projection): Linear(in_features=768, out_features=512, bias=True)\n    (gelu): GELU(approximate='none')\n    (fc): Linear(in_features=512, out_features=512, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n  (text_projection): ProjectionHead(\n    (projection): Linear(in_features=512, out_features=512, bias=True)\n    (gelu): GELU(approximate='none')\n    (fc): Linear(in_features=512, out_features=512, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n)"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "clip.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T07:59:15.890573Z",
     "start_time": "2024-04-10T07:59:15.880373Z"
    }
   },
   "id": "ba757d184fb61c5b",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[12.4456]], grad_fn=<MmBackward0>)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "image = Image.open(\"data/Images/1000268201_693b08cb0e.jpg\")\n",
    "text = \"A child in a pink dress is climbing up a set of stairs in an entry way .\"\n",
    "\n",
    "_, _, text_features, image_features = clip(image, text)\n",
    "\n",
    "# Import softmax function\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Calculate the similarity score\n",
    "similarity = text_features @ image_features.T\n",
    "similarity\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T08:00:43.245530Z",
     "start_time": "2024-04-10T08:00:42.968194Z"
    }
   },
   "id": "cfac515249deae0e",
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/Images/1000268201_693b08cb0e.jpg'\n",
      " 'data/Images/1001773457_577c3a7d70.jpg'\n",
      " 'data/Images/1002674143_1b742ab4b8.jpg'\n",
      " 'data/Images/1003163366_44323f5815.jpg']\n",
      "['A child in a pink dress is climbing up a set of stairs in an entry way .'\n",
      " 'A black dog and a spotted dog are fighting'\n",
      " 'A little girl covered in paint sits in front of a painted rainbow with her hands in a bowl .'\n",
      " 'A man lays on a bench while his dog sits by him .']\n"
     ]
    }
   ],
   "source": [
    "# Select 10 examples for testing\n",
    "test_images = images[:4]\n",
    "test_captions = captions[:4]\n",
    "print(test_images)\n",
    "print(test_captions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T08:00:45.543458Z",
     "start_time": "2024-04-10T08:00:45.538386Z"
    }
   },
   "id": "29d737b78aafa014",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[12.9002]], grad_fn=<MmBackward0>)"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "image = Image.open(\"data/Images/1001773457_577c3a7d70.jpg\")\n",
    "text = \"A black dog and a spotted dog are fighting\"\n",
    "\n",
    "_, _, text_features, image_features = clip(image, text)\n",
    "\n",
    "# Import softmax function\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Calculate the similarity score\n",
    "similarity = text_features @ image_features.T\n",
    "similarity\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T08:01:25.824182Z",
     "start_time": "2024-04-10T08:01:25.552048Z"
    }
   },
   "id": "ec11adbe683a132e",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "test_image = ['data/Images/1000268201_693b08cb0e.jpg',\n",
    "              'data/Images/1001773457_577c3a7d70.jpg',\n",
    "              'data/Images/1002674143_1b742ab4b8.jpg',\n",
    "              'data/Images/1003163366_44323f5815.jpg']\n",
    "test_text = ['A child in a pink dress is climbing up a set of stairs in an entry way .',\n",
    "             'A black dog and a spotted dog are fighting',\n",
    "             'A little girl covered in paint sits in front of a painted rainbow with her hands in a bowl .',\n",
    "             'A man lays on a bench while his dog sits by him .']\n",
    "\n",
    "\n",
    "\n",
    "# Pass test data through model\n",
    "t_im = Image.open('data/Images/1002674143_1b742ab4b8.jpg')\n",
    "test_image = [Image.open(image) for image in test_image]\n",
    "_, _, test_text_features, test_image_features = clip(test_image[0], test_text[0])\n",
    "\n",
    "# Compute similarity scores\n",
    "for i in range(1, len(test_image)):\n",
    "    _, _, text_features, image_features = clip(test_image[i], test_text[i])\n",
    "    test_text_features = torch.cat((test_text_features, text_features), dim=0)\n",
    "    test_image_features = torch.cat((test_image_features, image_features), dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T08:02:12.460146Z",
     "start_time": "2024-04-10T08:02:11.466839Z"
    }
   },
   "id": "8c0cfaa23408af9c",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 3.4426e-01, -4.8625e-01,  3.6989e-01,  1.9431e-01, -8.1173e-02,\n           1.5413e-01,  5.5961e-01, -6.9249e-01, -9.1896e-01,  2.4130e-01,\n           1.7374e-02, -9.3727e-02,  2.5287e+00, -1.3002e+00,  5.4595e-01,\n          -2.7917e-01, -1.4924e+00, -7.3973e-01, -9.0295e-01, -1.3562e-01,\n          -7.8348e-01, -7.8147e-01,  2.0823e-01, -4.8749e-01, -9.5894e-01,\n           9.2712e-01,  4.2492e-01, -2.3245e-02,  1.5966e-01,  6.9062e-01,\n           4.6569e-01,  5.1678e-01,  1.6644e-03,  2.4607e-01,  8.7628e-01,\n           3.2009e-01, -3.1724e+00,  3.0375e-02, -4.8416e-01,  1.6206e-01,\n           3.1184e-01,  4.8356e-01, -1.0057e+00, -1.6305e+00, -2.9304e-01,\n          -2.2038e-01, -1.9418e+00,  5.0844e-01, -1.2323e+00,  1.4476e-01,\n           3.4318e-01, -6.2782e-02, -1.1870e+00,  5.0257e-01,  1.7101e+00,\n           4.5517e-01, -5.5623e-01,  4.5230e-02, -5.5685e-01, -9.3072e-02,\n           6.5650e-01, -9.4037e-01, -8.2675e-01, -7.7307e-02, -1.4902e-01,\n          -2.2339e-01,  7.3005e-01,  1.7585e+00,  8.2189e-01,  4.6812e-01,\n          -2.2744e-01,  1.8455e-01,  2.1966e-01, -4.4051e-01,  1.8460e+00,\n          -6.9912e-01, -1.5534e+00,  2.0924e-01, -1.3176e+00, -2.4323e-01,\n          -7.1226e-01,  2.8001e-01,  3.6745e-02,  4.7968e-01, -3.6996e-01,\n           2.5208e-01, -2.0218e-01, -1.2127e+00, -1.4665e-01, -4.3634e-02,\n          -2.3394e-01,  1.2087e+00,  1.8414e+00, -4.8821e-01, -1.5292e+00,\n           7.1755e-03,  1.3304e+00, -9.6927e-01,  6.6240e-01, -3.5152e-01,\n           1.5878e-01, -1.9130e-01, -1.9827e+00, -1.2327e-01,  1.4204e+00,\n           8.4058e-02, -2.6087e-01, -1.2770e+00,  1.9324e-01, -9.4617e-01,\n           1.2049e+00,  2.7681e-01, -6.1799e-01,  1.6627e+00, -1.7692e+00,\n           1.6970e+00,  1.7633e+00, -1.2488e+00,  9.9122e-02,  7.1078e-01,\n           4.8433e-01,  3.6484e-02, -5.2622e-02, -7.3237e-01, -2.2362e-01,\n           1.1966e-01,  4.2243e-01,  4.2895e-02,  7.0515e-01,  8.7191e-02,\n          -3.4928e-01,  7.8520e-02,  4.0258e-03, -1.7180e-01,  9.0478e-01,\n           1.3131e-01,  1.4799e+00, -2.3505e+00, -8.8792e-02,  2.8238e-01,\n           5.5732e-01,  1.4433e+00, -2.8254e+00,  3.1162e-01,  1.0085e+00,\n          -4.0345e-01,  6.0090e-01,  5.1501e-01, -1.5329e-01,  3.8821e-01,\n           5.1319e-01,  1.1583e+00, -3.1652e+00,  3.5338e-01, -7.2775e-01,\n          -1.7900e-02,  1.0390e+00, -3.2344e-01,  6.6156e-01,  7.4672e-01,\n          -3.3934e-01, -6.0056e-01,  3.3714e+00, -1.0360e+00,  4.7399e-01,\n           7.9493e-01,  1.1735e+00,  3.5241e-01,  3.2944e-01,  1.9278e+00,\n          -1.8156e+00, -1.5914e-01,  2.1012e-02,  1.1250e+00,  5.9023e-01,\n           7.9173e-01,  4.5291e-01, -1.0874e+00,  7.2828e-03, -5.2991e-01,\n          -2.2246e+00,  7.8016e-03,  1.8347e-01,  4.8536e-01, -1.0638e-01,\n          -2.2280e+00,  7.5873e-01, -2.6838e-01, -3.6777e-01, -1.5654e+00,\n          -5.5668e-02,  4.3315e-01, -1.1339e+00, -4.6101e+00, -1.9478e-01,\n           4.7187e-02, -2.2743e-01,  9.3641e-01, -4.6491e-01, -4.5518e-01,\n           1.4057e-01, -1.1285e+00,  1.6672e-01,  1.8192e-02, -2.2547e-02,\n           4.2683e-01,  6.4563e-01, -1.4310e+00,  1.0184e+00, -3.2920e-01,\n           8.1966e-01,  7.5237e-01,  1.9599e-01,  1.2821e-01,  5.3421e-01,\n          -4.0427e-01,  2.5201e-01, -3.5933e+00, -2.0558e-01, -1.2396e+00,\n           1.8422e+00,  3.0054e-01,  2.2378e-01,  7.9375e-01,  3.3071e-01,\n          -8.8328e-01, -1.1214e-01,  1.3486e-01,  4.4971e-01, -7.7091e-01,\n           8.0140e-02, -3.5747e+00, -1.2630e+00, -2.1495e-01, -2.3278e-01,\n           8.5173e-01,  1.0322e+00, -1.4189e-01, -1.2716e+00, -2.1080e-01,\n          -3.9149e-01, -1.4304e-02,  1.6538e-01, -3.9014e-01, -2.6726e+00,\n           1.6624e+00, -1.8375e-01, -4.7871e-01,  4.7744e-01,  2.1046e+00,\n           1.3142e+00, -4.2145e-01,  3.9669e-01, -1.5023e+00,  1.1585e-01,\n           1.7394e+00,  9.6164e-01,  3.4844e-01, -1.3565e+00, -9.8808e-01,\n           2.5944e-01, -1.0435e+00, -4.9008e-01,  1.2522e+00,  1.6188e-01,\n           8.5656e-02,  1.9775e-01,  4.3096e-01, -3.7397e+00, -5.9373e-02,\n          -9.5628e-01,  7.2301e-01, -5.2070e-02,  5.0591e-02, -3.4646e-02,\n           5.9896e-01,  1.6753e+00, -4.9280e-01,  1.1144e+00,  2.1645e+00,\n          -2.9521e-01, -5.6100e-01,  1.6102e-01, -2.5248e-02, -4.1094e-01,\n           1.2679e+00, -5.2983e-01,  5.6729e-02, -2.0021e-01, -3.7837e-01,\n           1.2756e-01,  3.5555e-02,  3.0210e-02, -7.9968e-01, -7.9780e-01,\n           2.2292e-01,  1.3227e+00,  1.1362e+00, -2.3209e+00,  9.6229e-01,\n          -3.6064e-04, -3.1528e-01, -6.1182e-01,  5.8153e-01, -3.6014e-02,\n          -6.6350e-01, -1.7339e+00,  2.4018e-01, -8.7321e-02,  2.8080e-01,\n           7.3771e-01, -1.1145e-01,  1.4149e+00, -3.2117e-01, -1.0437e+00,\n          -1.5819e+00, -2.8603e-01, -1.8440e+00, -4.0636e-01,  4.8046e-01,\n          -1.3228e+00, -1.4423e-01, -3.8260e-02,  3.8941e-01, -1.2225e-01,\n          -4.1691e-01, -6.4169e-01,  1.6212e+00,  4.0857e-01, -4.0438e-02,\n           1.3160e+00,  4.0513e-02,  9.7964e-01,  1.3926e-01,  2.2627e-01,\n          -1.5978e+00, -1.8850e+00, -1.5276e+00, -3.7639e-01,  1.0563e+00,\n           4.5937e-01,  1.4654e+00, -6.5437e-01, -5.6214e-01, -6.0900e-01,\n           1.8041e+00, -1.9320e-01,  8.8753e-04,  3.3841e-01, -5.0502e-01,\n          -4.6715e-01,  1.2692e+00,  3.0518e-01, -7.2142e-02, -2.8500e-01,\n          -5.5654e-01, -3.1785e-01,  1.8788e-02,  2.6360e-01,  3.3260e-01,\n          -3.1439e-01, -1.9609e+00,  7.6289e-02,  2.3182e+00, -3.3698e-01,\n           7.6169e-01,  6.6964e-01, -8.8006e-01,  2.3820e-01,  4.0622e-02,\n          -8.5185e-01,  2.4077e-01, -4.5719e-01,  7.5758e-01,  5.0165e-01,\n          -3.2128e-01,  3.8814e-01, -1.0514e+00,  2.0002e+00,  4.9492e-01,\n          -9.5846e-02,  1.5020e+00, -1.4083e+00,  3.5113e-01, -1.0544e+00,\n           1.6330e+00, -3.2443e-01, -7.1609e-01,  1.9783e-02, -6.3543e-01,\n          -2.6045e-02, -1.7380e-01,  7.0780e-01, -9.4391e-01,  5.8555e-01,\n          -6.3988e-01, -2.1481e-01,  1.2005e+00, -3.7536e-01,  3.4566e-01,\n          -1.9885e-01, -4.0161e-01,  8.6405e-01, -9.4456e-01,  9.1800e-01,\n          -1.2207e-01, -5.5505e-01, -8.0330e-01,  1.0628e+00, -5.5948e-02,\n           7.6521e-01, -4.9554e-01, -3.6801e+00, -1.0321e-01, -2.6667e+00,\n          -7.2683e-01,  6.0897e-01,  5.7696e-02, -8.0508e-02, -5.7994e-02,\n           5.7757e-01,  7.4182e-01, -6.4488e-02, -1.8715e+00, -7.2032e-01,\n           1.7656e+00,  6.8000e-01,  3.2489e-01, -4.1509e-01,  1.6182e-01,\n           1.1645e+00,  1.8360e+00,  1.9900e-01, -5.5860e-01,  5.1499e-01,\n           4.3917e-01,  1.6622e+00, -4.8626e-01,  5.7047e-01,  9.8549e-01,\n           4.5133e-01, -9.5623e-02, -8.0172e-01,  2.8537e-01,  3.8249e-01,\n          -5.5319e-01, -8.2662e-01, -3.2799e-01, -3.1167e-01,  7.6156e-01,\n          -2.7434e-01,  2.9540e-01, -9.7565e-01,  3.5639e-01,  5.6273e-02,\n          -4.7299e-01,  4.4911e-01, -1.4668e-01, -1.5673e+00, -6.9013e-01,\n           7.4452e-01,  8.4753e-01, -1.8738e-01,  9.4782e-01, -7.5318e-01,\n          -5.5555e-01, -8.2841e-01, -5.9216e-01,  2.0638e+00, -4.1998e-01,\n          -7.9149e-01, -1.3153e-01, -1.7969e-01,  2.2435e+00,  8.7644e-01,\n           4.0917e-01,  1.0697e+00,  4.5495e-01,  2.0116e-01,  4.9368e-02,\n           1.1788e+00,  1.3530e+00, -3.0331e-01, -5.1739e-01,  1.0596e+00,\n           1.4718e-01, -4.3519e-01, -1.4039e-01, -7.8866e-01,  2.3417e+00,\n           2.9681e-01,  1.3973e+00,  5.9213e-01,  2.7954e+00,  3.9475e-01,\n          -9.0922e-01,  1.3607e+00, -8.9993e-01, -6.2311e-01, -3.2124e-01,\n           7.5943e-01, -2.1580e-01, -4.5702e-02,  1.2596e-01,  3.3370e+00,\n           6.2730e-01,  1.4586e-01,  2.3547e+00,  1.8350e+00, -9.0016e-01,\n          -1.4724e+00,  3.8144e-01]], grad_fn=<NativeLayerNormBackward0>),\n tensor([[ 1.2986e-01, -5.2803e-02,  1.3385e+00,  9.3828e-01, -1.1693e+00,\n          -2.3874e+00,  2.6763e+00,  3.7747e-01, -6.3069e-01,  9.6696e-01,\n          -2.8087e-01,  5.5578e-01,  1.9665e-01,  4.9435e-01,  4.6690e-02,\n           1.3181e+00, -5.2604e-01,  6.7638e-01, -1.3232e+00,  1.2943e+00,\n          -7.4889e-01,  3.4346e-01,  1.4026e+00,  6.3095e-01,  5.1234e-02,\n           2.8561e-01, -1.7299e+00,  1.4330e-01,  9.8934e-01,  1.2591e+00,\n          -8.6621e-01,  7.4073e-01, -2.0084e+00,  7.7771e-01, -1.2152e+00,\n          -5.2004e-01,  6.0657e-01,  6.3167e-01,  9.4185e-01, -2.6058e-02,\n           2.4570e+00,  5.1343e-01,  5.5406e-02,  1.0270e-01, -1.5779e-01,\n          -1.4108e+00,  2.9742e-01, -1.1931e+00,  8.5901e-01,  5.1139e-01,\n          -3.2080e-02,  1.3128e+00, -3.4250e-01, -7.2537e-02, -1.4841e-01,\n          -2.0066e-02, -1.1538e+00,  1.4349e+00, -3.9371e-01, -8.1315e-01,\n           2.7076e-01,  3.1175e-01, -2.2927e-01,  2.1548e+00, -1.5706e-02,\n          -2.4143e+00, -6.7860e-02,  1.3501e+00, -2.7493e+00,  4.9780e-01,\n           8.3902e-01, -1.7535e+00,  7.8147e-01,  6.1949e-02,  2.8935e-01,\n          -1.5113e-02,  4.1992e-01,  7.5499e-01,  8.4635e-03, -1.3275e+00,\n           7.2043e-01,  7.4290e-01, -1.6869e+00, -1.8891e-01, -1.1195e-01,\n           2.2928e-01,  3.0857e-01, -6.7356e-01, -6.1136e-01,  2.0955e-01,\n           1.4644e-01,  8.7166e-01, -4.1154e-01,  2.5091e-01, -5.5574e-01,\n           3.1119e+00, -1.2154e+00, -7.3791e-01,  2.8689e+00,  1.6496e-01,\n          -1.0754e+00, -6.3296e-01, -2.5002e-01, -4.9877e-01, -3.3646e-02,\n          -1.6648e+00,  7.0851e-01, -9.6673e-01,  4.5547e-01, -1.2040e+00,\n           5.5261e-01, -5.1278e-01,  9.8702e-01,  5.1982e-01,  2.3336e-01,\n           2.5379e-01, -3.2675e-01,  7.4176e-01, -1.6056e+00, -5.9839e-01,\n           7.1801e-01, -5.0517e-02, -1.7417e-01, -2.1732e-01,  3.4729e-01,\n           1.2947e-01,  1.4072e+00,  7.0060e-01,  4.8952e-01,  4.4187e-02,\n           1.1619e-01,  5.9920e-01, -3.0084e-01,  3.0835e-01, -8.0136e-01,\n          -2.2426e+00,  4.1126e-01, -3.8285e-01,  7.2122e-01, -2.8094e-01,\n           6.1110e-01,  6.3816e-03, -4.9027e-01,  8.5480e-01,  3.2441e-01,\n           1.6535e+00, -9.0020e-01, -1.4981e+00, -8.3284e-01,  5.7391e-01,\n          -1.1885e+00,  1.4498e+00, -6.2972e-01,  1.3989e+00,  5.9074e-01,\n          -9.0763e-01,  4.1694e-01, -2.1717e+00,  4.3192e-01,  1.8822e+00,\n          -9.1822e-01, -7.6742e-01, -4.6892e-03, -6.1009e-01,  8.0619e-01,\n          -6.8670e-01,  5.7922e-02, -1.9795e+00,  8.8973e-01,  6.2836e-01,\n          -3.5864e-01,  9.9186e-01,  1.1139e-01, -4.0335e-01,  3.6227e-01,\n          -5.3452e-01, -7.1626e-02, -2.7882e-01,  1.0534e-01, -2.0094e-02,\n           1.1663e-01,  1.9334e-01, -1.0056e+00, -3.2852e-02,  9.3943e-01,\n          -2.0813e-01,  1.1415e-01,  1.4639e-01,  3.7480e-02, -2.0679e-03,\n           1.2911e+00,  4.1003e-01, -7.2508e-01, -7.6654e-02,  1.2361e+00,\n          -6.4756e-01, -4.0256e+00, -6.8601e-01, -2.4084e+00,  7.8936e-01,\n          -3.1438e+00,  2.5127e-01,  8.2168e-01, -5.2163e-01, -2.8030e-01,\n          -4.3757e-01,  1.1714e+00, -3.1143e-02,  5.4303e-02,  1.0381e+00,\n          -7.2250e-01,  1.0628e+00, -4.4470e-01, -2.5808e-01,  1.2778e+00,\n          -2.6882e+00,  3.4556e-02, -5.7383e-02, -9.3216e-02, -7.5007e-02,\n           1.0381e-01,  4.9989e-01,  4.7547e-01,  3.6413e-01,  9.7064e-01,\n          -2.0882e-01, -9.0271e-01,  5.8601e-01,  1.3259e+00,  7.5915e-01,\n           2.7798e-01, -1.0127e+00, -5.0002e-02, -3.5588e-01, -7.5512e-01,\n          -3.9750e-01,  7.5991e-02,  7.0882e-01, -3.0409e-01,  2.8357e-01,\n           1.6404e-01, -1.1549e-01,  8.5390e-01,  3.7550e-01,  3.5571e-01,\n           2.6471e-01,  4.7310e-02, -3.9951e-01,  6.4411e-01,  1.9404e-01,\n          -9.8236e-01, -1.4842e+00, -9.5556e-01,  3.3764e-01,  1.8927e+00,\n          -7.2461e-01, -5.6830e-02,  1.8638e+00, -4.8758e-02, -6.2564e-01,\n          -2.2674e+00,  4.6437e-01, -3.1739e-01,  8.7938e-01, -1.6358e+00,\n           4.9131e-01,  2.0851e+00, -4.5673e-01, -1.0577e+00, -6.0313e-01,\n          -2.6147e-01,  1.5970e+00, -6.5185e-01,  2.1497e+00,  2.6041e-01,\n           1.1411e-01,  1.5904e-01, -2.6238e+00, -2.8041e-01,  4.1706e-01,\n           6.8985e-01, -1.9827e-01,  3.3072e-01,  1.5817e-01,  4.8701e-02,\n          -2.7581e-02, -9.2777e-02,  3.9047e-01, -8.1709e-01, -1.4581e-01,\n          -1.0463e+00, -1.1967e+00, -7.3342e-01, -3.8052e-01, -4.1739e-01,\n           8.5055e-01,  3.2180e-01,  6.8715e-02, -1.0949e-01,  4.1099e-01,\n           3.2435e-01, -1.1361e+00,  4.9493e-01, -6.9269e-02, -1.7910e+00,\n           4.2028e-01,  1.1408e-01, -1.6272e+00,  4.6866e-01,  1.0665e+00,\n           3.5267e-01,  2.6158e-01,  5.6050e-01,  5.3167e-01,  1.8386e-01,\n          -2.3470e-01,  5.5218e-02,  5.4976e-01,  9.5111e-02,  6.5301e-01,\n          -2.6229e-01,  1.1154e+00,  1.5882e+00,  5.7740e-01,  9.5903e-01,\n          -2.3181e+00,  5.7427e-02,  1.1146e+00, -7.5497e-01, -1.3711e-01,\n          -3.8157e-01,  1.0647e+00, -1.5607e+00, -2.8062e-01,  9.2188e-01,\n          -6.3307e-01, -1.8639e-01, -1.8892e-01, -2.2388e-01,  8.6583e-01,\n           2.9335e-01,  3.1224e-02, -1.5429e+00, -5.1067e-01, -4.8858e-01,\n           1.6165e-01,  8.5243e-01, -1.9202e+00, -9.9716e-01, -7.0819e-01,\n           4.5336e-01,  6.2021e-01,  1.8653e+00, -1.6766e+00,  1.8446e+00,\n           9.2369e-01, -4.3554e-01,  1.3111e+00,  5.9822e-01, -3.3102e+00,\n          -2.9707e+00,  3.8119e-02,  3.1234e+00, -8.8347e-02, -2.0115e+00,\n          -8.5576e-01, -2.2160e+00, -5.9610e-01, -2.3616e+00, -2.7835e+00,\n           2.6259e+00, -5.1836e-02, -9.2342e-01,  9.6288e-01,  4.7422e-01,\n          -5.1707e-01,  1.4556e+00,  1.8081e+00,  1.3186e-01, -9.4762e-01,\n           1.1719e+00,  9.6539e-01, -5.6109e-02, -1.2715e+00,  2.7345e-01,\n           6.0220e-01, -6.5694e-01,  9.0155e-01, -2.4996e-01,  1.2522e+00,\n          -1.3294e-01,  1.4229e-01,  4.9187e-01, -5.1200e-01,  1.2284e+00,\n          -1.3259e+00,  6.6185e-01, -2.1049e-01,  1.6862e-01, -1.6805e+00,\n           1.1012e+00, -2.2230e-01, -1.1761e+00, -5.5539e-01,  6.9423e-02,\n          -3.3284e-02,  5.0157e-01, -6.2229e-01,  1.1217e+00,  3.0791e-01,\n          -5.0374e-01,  3.5938e-01,  8.1700e-01,  4.6351e-01,  1.3665e-01,\n          -9.8784e-01, -1.0584e+00, -1.3784e-02, -5.7514e-01, -1.2268e+00,\n          -1.6948e+00, -4.0477e-02, -8.2424e-01,  3.7918e-01,  3.3489e+00,\n          -1.0995e-01, -3.6815e-01,  9.6779e-01, -1.5157e+00,  1.9700e-01,\n           2.6906e-01,  3.0010e-01,  3.0603e-01,  3.1452e+00,  9.5184e-01,\n          -1.3197e+00, -6.7236e-02,  3.1875e-02, -7.0351e-01, -1.0629e+00,\n           1.5754e-01,  1.1751e+00,  1.3172e+00, -8.7695e-01,  6.7200e-01,\n           2.2592e-01,  1.9028e-02,  5.5325e-01, -7.4036e-02, -6.9658e-01,\n           2.7151e-01,  1.2166e+00, -6.2347e-01, -1.0576e+00, -4.0045e-02,\n          -2.8412e-01,  4.0590e-01, -4.5448e-02,  3.4663e-02,  6.5121e-01,\n           3.1554e-02, -7.8311e-01,  1.0051e+00, -1.1181e+00,  6.0174e-02,\n          -1.7045e-02, -1.3008e-01,  7.7050e-01,  1.0789e+00, -2.4927e-01,\n          -7.6832e-01,  4.7837e-01, -2.7149e+00, -1.7243e-02,  1.1848e+00,\n           8.9319e-01, -1.6889e-01,  1.4130e-01,  6.5441e-01,  2.1386e-01,\n          -5.9217e-02,  4.4988e-01, -2.4444e-01,  1.8330e-01,  2.7081e-01,\n          -7.4347e-02,  3.3851e-01,  4.5695e-01, -3.9910e-03, -1.6564e-01,\n          -1.5078e-01,  1.1486e-01, -8.4441e-01, -1.0429e-01, -5.3119e-01,\n          -1.7308e+00,  3.9877e-01,  2.7678e-01, -3.8672e-01, -9.5540e-02,\n           5.5257e-01,  7.8545e-01,  8.8840e-02, -3.1942e+00, -1.6871e-01,\n           1.8445e+00,  9.8425e-01,  3.7131e-01, -6.9037e-01,  9.7580e-01,\n           3.8624e-01,  1.0679e+00]], grad_fn=<NativeLayerNormBackward0>))"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features, image_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T07:38:54.852107Z",
     "start_time": "2024-04-10T07:38:54.823262Z"
    }
   },
   "id": "f8980e6a2fec2d72",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "similarity_scores = test_text_features @ test_image_features.T\n",
    "similarity_scores = similarity_scores.detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T08:02:58.177113Z",
     "start_time": "2024-04-10T08:02:58.172213Z"
    }
   },
   "id": "5ede4b7ab3d3ee69",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08687177 0.4575418  0.10596867 0.34961778]\n",
      " [0.09747648 0.47073233 0.11141967 0.32037115]\n",
      " [0.07930483 0.47848603 0.0993202  0.34288827]\n",
      " [0.06628865 0.47623667 0.09041051 0.36706358]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "# Apply softmax along rows\n",
    "softmax_scores = softmax(similarity_scores, axis=1)\n",
    "\n",
    "print(softmax_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-10T08:02:58.841373Z",
     "start_time": "2024-04-10T08:02:58.835685Z"
    }
   },
   "id": "2d762b8873cc6cfc",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8366f2e08fab74e9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
